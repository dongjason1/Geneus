{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLPRjP9qB3rQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/art81/geneus\" target=\"_blank\">https://app.wandb.ai/art81/geneus</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/art81/geneus/runs/3mrteda9\" target=\"_blank\">https://app.wandb.ai/art81/geneus/runs/3mrteda9</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "from wandb import magic\n",
    "wandb.init(project=\"geneus\")\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Flatten,Input,Reshape\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import random\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cCuhszKzCPI4"
   },
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QzEoyDPCM-F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2483]\n",
      " [ 1632]\n",
      " [ 2098]\n",
      " [  500]\n",
      " [ 7636]\n",
      " [  392]\n",
      " [  251]\n",
      " [ 5005]\n",
      " [ 3491]\n",
      " [ 1384]\n",
      " [  678]\n",
      " [ 1032]\n",
      " [  634]\n",
      " [  370]\n",
      " [  252]\n",
      " [  226]\n",
      " [  968]\n",
      " [  228]\n",
      " [  277]\n",
      " [  583]\n",
      " [ 1144]\n",
      " [ 4988]\n",
      " [ 1291]\n",
      " [10019]\n",
      " [ 6668]\n",
      " [ 1810]\n",
      " [ 4153]\n",
      " [  384]\n",
      " [ 1083]\n",
      " [  271]\n",
      " [ 5078]\n",
      " [  370]\n",
      " [  346]\n",
      " [18627]\n",
      " [  302]\n",
      " [  246]\n",
      " [ 1797]\n",
      " [ 1093]\n",
      " [ 1785]\n",
      " [  797]\n",
      " [ 2098]\n",
      " [ 1384]\n",
      " [  813]\n",
      " [  312]\n",
      " [ 1204]\n",
      " [ 1093]\n",
      " [  705]\n",
      " [  605]\n",
      " [  583]\n",
      " [ 4153]\n",
      " [  392]\n",
      " [ 1150]\n",
      " [ 1369]\n",
      " [  520]\n",
      " [  525]\n",
      " [  271]\n",
      " [ 5005]\n",
      " [  522]\n",
      " [ 3492]\n",
      " [ 1500]\n",
      " [ 2211]\n",
      " [ 1562]\n",
      " [  828]\n",
      " [ 5358]\n",
      " [ 5402]\n",
      " [ 1559]\n",
      " [  539]\n",
      " [ 2483]\n",
      " [ 2643]\n",
      " [ 1810]\n",
      " [  520]\n",
      " [ 1733]\n",
      " [  566]\n",
      " [  987]\n",
      " [ 2791]\n",
      " [  828]\n",
      " [ 2630]\n",
      " [ 2483]\n",
      " [ 5358]\n",
      " [  337]\n",
      " [ 1326]\n",
      " [  668]\n",
      " [  930]\n",
      " [  439]\n",
      " [  312]\n",
      " [ 5005]\n",
      " [  370]\n",
      " [ 2899]\n",
      " [  327]\n",
      " [ 5358]\n",
      " [  930]\n",
      " [  978]\n",
      " [ 1559]\n",
      " [  520]\n",
      " [ 3268]\n",
      " [  322]\n",
      " [  164]\n",
      " [  448]\n",
      " [ 6668]\n",
      " [ 1810]\n",
      " [ 4988]\n",
      " [  711]\n",
      " [  132]\n",
      " [ 2849]\n",
      " [  915]\n",
      " [ 1065]\n",
      " [  797]\n",
      " [ 8153]\n",
      " [  605]\n",
      " [  705]\n",
      " [  551]\n",
      " [  470]\n",
      " [ 1733]\n",
      " [ 2702]\n",
      " [  939]\n",
      " [ 2702]\n",
      " [  872]\n",
      " [  830]\n",
      " [  470]\n",
      " [ 1291]\n",
      " [  361]\n",
      " [ 1723]\n",
      " [  271]\n",
      " [ 5358]\n",
      " [  709]\n",
      " [ 2702]\n",
      " [  131]\n",
      " [  828]\n",
      " [  210]\n",
      " [  447]\n",
      " [  358]\n",
      " [ 5402]\n",
      " [  605]\n",
      " [ 2630]\n",
      " [ 1370]\n",
      " [  329]\n",
      " [  378]\n",
      " [  285]\n",
      " [ 1204]\n",
      " [  537]\n",
      " [  337]\n",
      " [  231]\n",
      " [  960]\n",
      " [  226]\n",
      " [ 1723]\n",
      " [  231]\n",
      " [  470]\n",
      " [  330]\n",
      " [ 8602]\n",
      " [  179]\n",
      " [ 1384]\n",
      " [ 5358]\n",
      " [  273]\n",
      " [  459]\n",
      " [ 2035]\n",
      " [  422]\n",
      " [ 2630]\n",
      " [  700]\n",
      " [  605]\n",
      " [  286]\n",
      " [ 5358]\n",
      " [ 6668]\n",
      " [  228]\n",
      " [ 5358]\n",
      " [  363]\n",
      " [  556]\n",
      " [ 1384]\n",
      " [ 2692]\n",
      " [  277]\n",
      " [  797]\n",
      " [ 2483]\n",
      " [  304]\n",
      " [ 2557]\n",
      " [  304]\n",
      " [  520]\n",
      " [  271]\n",
      " [ 4396]\n",
      " [  343]\n",
      " [  582]\n",
      " [24825]\n",
      " [ 1632]\n",
      " [ 1083]\n",
      " [  856]\n",
      " [  593]\n",
      " [  245]\n",
      " [ 2630]\n",
      " [  345]\n",
      " [  243]\n",
      " [  763]\n",
      " [  734]\n",
      " [  373]\n",
      " [  398]\n",
      " [  810]\n",
      " [  422]\n",
      " [  556]\n",
      " [ 1065]\n",
      " [  968]\n",
      " [  215]\n",
      " [  554]\n",
      " [ 1810]\n",
      " [  312]\n",
      " [  363]\n",
      " [  327]\n",
      " [ 1821]\n",
      " [ 2553]\n",
      " [  705]\n",
      " [ 3509]\n",
      " [  322]\n",
      " [  512]\n",
      " [ 1091]\n",
      " [ 1291]\n",
      " [  289]\n",
      " [ 2483]\n",
      " [  520]\n",
      " [  629]\n",
      " [ 1631]\n",
      " [  678]\n",
      " [ 1093]\n",
      " [ 4153]\n",
      " [  946]\n",
      " [  480]\n",
      " [  239]\n",
      " [  271]\n",
      " [  626]\n",
      " [ 2553]\n",
      " [ 1093]\n",
      " [  228]\n",
      " [  929]\n",
      " [  208]\n",
      " [18627]\n",
      " [ 2791]\n",
      " [ 2055]\n",
      " [  392]\n",
      " [ 2899]\n",
      " [ 3822]\n",
      " [ 4988]\n",
      " [  604]\n",
      " [  556]\n",
      " [ 2483]\n",
      " [ 6668]\n",
      " [ 1685]\n",
      " [ 3990]\n",
      " [ 5358]\n",
      " [  515]\n",
      " [  840]\n",
      " [  480]\n",
      " [  338]\n",
      " [  226]\n",
      " [ 1562]\n",
      " [  277]\n",
      " [ 1428]\n",
      " [  388]\n",
      " [  830]\n",
      " [  378]\n",
      " [  404]\n",
      " [  510]\n",
      " [  582]\n",
      " [ 3265]\n",
      " [  734]\n",
      " [  370]\n",
      " [  374]\n",
      " [ 3491]\n",
      " [ 2098]\n",
      " [  808]\n",
      " [ 5358]\n",
      " [ 1631]\n",
      " [22242]\n",
      " [ 3491]\n",
      " [  978]\n",
      " [  830]\n",
      " [  276]\n",
      " [ 3268]\n",
      " [ 5057]\n",
      " [  980]\n",
      " [ 1810]\n",
      " [  604]\n",
      " [ 5358]\n",
      " [  293]\n",
      " [  304]\n",
      " [  337]\n",
      " [  566]\n",
      " [  583]\n",
      " [ 5358]\n",
      " [  417]\n",
      " [ 1316]\n",
      " [  273]\n",
      " [ 1093]\n",
      " [  336]\n",
      " [ 4988]\n",
      " [  678]\n",
      " [  930]\n",
      " [ 1370]\n",
      " [  132]\n",
      " [ 1091]\n",
      " [ 2098]\n",
      " [  554]\n",
      " [ 1083]\n",
      " [  856]\n",
      " [  289]\n",
      " [22242]\n",
      " [  392]\n",
      " [  629]\n",
      " [  586]\n",
      " [  246]\n",
      " [ 2095]\n",
      " [  571]\n",
      " [ 1632]\n",
      " [  373]\n",
      " [  271]\n",
      " [ 4153]\n",
      " [  968]\n",
      " [  632]\n",
      " [  596]\n",
      " [ 3268]\n",
      " [  445]\n",
      " [ 7636]\n",
      " [ 2899]\n",
      " [  923]\n",
      " [  828]\n",
      " [ 8602]\n",
      " [ 4396]\n",
      " [  373]\n",
      " [ 1594]\n",
      " [  271]\n",
      " [  638]\n",
      " [  449]\n",
      " [ 1093]\n",
      " [ 2483]\n",
      " [  592]\n",
      " [ 2692]\n",
      " [  337]\n",
      " [ 5402]\n",
      " [  480]\n",
      " [ 3509]\n",
      " [ 2791]\n",
      " [  312]\n",
      " [ 1091]\n",
      " [ 4153]\n",
      " [  939]\n",
      " [ 5358]\n",
      " [  602]\n",
      " [  373]\n",
      " [  593]\n",
      " [ 2098]\n",
      " [ 3492]\n",
      " [  296]\n",
      " [  359]\n",
      " [  266]\n",
      " [  939]\n",
      " [  304]\n",
      " [  289]\n",
      " [  592]\n",
      " [24825]\n",
      " [  568]\n",
      " [ 1632]\n",
      " [  298]\n",
      " [  678]\n",
      " [  946]\n",
      " [  577]\n",
      " [  705]\n",
      " [  274]\n",
      " [ 2791]\n",
      " [ 1632]\n",
      " [  840]\n",
      " [ 1316]\n",
      " [  252]\n",
      " [  289]\n",
      " [ 8602]\n",
      " [  813]\n",
      " [ 8153]\n",
      " [ 4843]\n",
      " [ 1370]\n",
      " [ 1083]\n",
      " [ 2211]\n",
      " [  304]\n",
      " [  378]\n",
      " [  286]\n",
      " [ 2098]\n",
      " [  419]\n",
      " [ 4153]\n",
      " [  520]\n",
      " [  356]\n",
      " [ 1091]\n",
      " [  840]\n",
      " [  914]\n",
      " [  370]\n",
      " [  577]\n",
      " [  666]\n",
      " [  289]\n",
      " [ 2899]\n",
      " [ 1594]\n",
      " [  813]\n",
      " [ 4153]\n",
      " [ 2483]\n",
      " [ 4988]\n",
      " [  629]\n",
      " [  793]\n",
      " [  336]\n",
      " [  312]\n",
      " [  553]\n",
      " [  525]\n",
      " [ 2630]\n",
      " [ 2941]\n",
      " [ 7636]\n",
      " [ 1384]\n",
      " [  337]\n",
      " [ 1707]\n",
      " [ 2630]\n",
      " [ 2800]\n",
      " [  470]\n",
      " [ 3212]\n",
      " [ 2098]\n",
      " [  915]\n",
      " [ 4153]\n",
      " [  556]\n",
      " [ 1632]\n",
      " [ 2035]\n",
      " [  378]\n",
      " [  801]\n",
      " [  436]\n",
      " [  930]\n",
      " [  287]\n",
      " [  277]\n",
      " [ 1500]\n",
      " [ 4029]\n",
      " [  125]\n",
      " [   41]\n",
      " [  190]\n",
      " [ 2702]\n",
      " [  936]\n",
      " [  806]\n",
      " [  124]\n",
      " [  602]\n",
      " [  361]\n",
      " [  153]\n",
      " [  172]\n",
      " [  125]\n",
      " [  144]\n",
      " [  147]\n",
      " [  202]\n",
      " [  139]\n",
      " [ 4029]\n",
      " [ 1282]\n",
      " [  108]\n",
      " [  128]\n",
      " [  130]\n",
      " [  108]\n",
      " [  155]\n",
      " [  806]\n",
      " [  936]\n",
      " [  179]\n",
      " [ 2702]\n",
      " [  112]\n",
      " [  229]\n",
      " [  152]\n",
      " [  107]\n",
      " [  166]\n",
      " [  119]\n",
      " [  114]\n",
      " [  231]\n",
      " [  197]\n",
      " [  112]\n",
      " [  308]\n",
      " [  147]\n",
      " [  996]\n",
      " [  381]\n",
      " [  512]\n",
      " [  433]\n",
      " [ 1086]\n",
      " [ 1269]\n",
      " [  267]\n",
      " [ 1207]\n",
      " [ 1030]\n",
      " [ 1938]\n",
      " [  896]\n",
      " [  799]\n",
      " [  282]\n",
      " [  465]\n",
      " [  389]\n",
      " [  407]\n",
      " [ 1054]\n",
      " [  664]\n",
      " [ 2140]\n",
      " [  304]\n",
      " [ 2345]\n",
      " [ 1779]\n",
      " [  854]\n",
      " [ 1282]\n",
      " [ 1184]\n",
      " [ 2551]\n",
      " [  369]\n",
      " [  738]\n",
      " [  543]\n",
      " [ 1142]\n",
      " [ 1103]\n",
      " [  807]\n",
      " [ 1151]\n",
      " [  470]\n",
      " [ 1565]\n",
      " [ 2495]\n",
      " [  864]\n",
      " [ 1323]\n",
      " [ 1620]\n",
      " [  926]\n",
      " [  363]\n",
      " [  495]\n",
      " [ 4862]\n",
      " [  626]\n",
      " [ 1201]\n",
      " [  459]\n",
      " [ 1556]\n",
      " [  424]\n",
      " [  441]\n",
      " [  778]\n",
      " [  692]\n",
      " [  412]\n",
      " [  942]\n",
      " [  388]\n",
      " [  944]\n",
      " [  718]\n",
      " [  543]\n",
      " [  949]\n",
      " [  449]\n",
      " [ 4083]\n",
      " [ 3881]\n",
      " [  106]\n",
      " [ 1631]\n",
      " [  825]\n",
      " [  369]\n",
      " [  463]\n",
      " [  558]\n",
      " [  442]\n",
      " [  772]\n",
      " [  462]\n",
      " [  841]\n",
      " [  789]\n",
      " [  540]\n",
      " [  428]\n",
      " [  957]\n",
      " [  471]\n",
      " [ 1049]\n",
      " [ 1839]\n",
      " [ 2327]\n",
      " [  238]\n",
      " [  818]\n",
      " [  219]\n",
      " [ 5085]\n",
      " [ 2838]\n",
      " [ 1041]\n",
      " [ 1112]\n",
      " [  654]\n",
      " [ 1285]\n",
      " [ 1420]\n",
      " [  679]\n",
      " [ 1052]\n",
      " [ 5574]\n",
      " [  469]\n",
      " [  627]\n",
      " [ 1584]\n",
      " [ 5583]\n",
      " [ 1738]\n",
      " [ 1254]\n",
      " [  840]\n",
      " [ 1340]\n",
      " [ 5790]\n",
      " [  865]\n",
      " [  801]\n",
      " [ 3755]\n",
      " [  678]\n",
      " [19080]\n",
      " [ 1224]\n",
      " [  195]\n",
      " [  153]\n",
      " [  138]\n",
      " [ 1018]\n",
      " [  778]\n",
      " [  257]\n",
      " [  270]\n",
      " [  258]\n",
      " [  193]\n",
      " [  497]\n",
      " [  223]\n",
      " [  211]\n",
      " [  213]\n",
      " [  189]\n",
      " [  420]\n",
      " [ 2008]\n",
      " [  212]\n",
      " [  848]\n",
      " [  192]\n",
      " [  336]\n",
      " [ 1734]\n",
      " [  143]\n",
      " [  259]\n",
      " [  235]\n",
      " [  190]\n",
      " [  190]\n",
      " [  151]\n",
      " [  430]\n",
      " [  153]\n",
      " [  363]\n",
      " [  558]\n",
      " [ 1518]\n",
      " [  198]\n",
      " [ 1475]\n",
      " [   88]\n",
      " [  680]\n",
      " [ 1823]\n",
      " [ 1508]\n",
      " [  292]\n",
      " [  151]\n",
      " [  116]\n",
      " [  131]\n",
      " [  372]\n",
      " [   85]\n",
      " [  792]\n",
      " [  271]\n",
      " [  189]\n",
      " [  155]\n",
      " [  233]\n",
      " [  281]\n",
      " [  835]\n",
      " [  156]\n",
      " [  155]\n",
      " [  832]\n",
      " [  225]\n",
      " [  213]\n",
      " [  669]\n",
      " [  156]\n",
      " [  275]\n",
      " [ 1991]\n",
      " [  214]\n",
      " [ 3856]\n",
      " [  499]\n",
      " [  672]\n",
      " [  255]\n",
      " [  261]\n",
      " [  793]\n",
      " [  154]\n",
      " [  304]\n",
      " [ 1505]\n",
      " [  158]\n",
      " [ 2664]\n",
      " [  274]\n",
      " [  222]\n",
      " [  233]\n",
      " [  149]\n",
      " [ 2156]\n",
      " [ 1649]\n",
      " [  251]\n",
      " [  750]\n",
      " [  199]\n",
      " [  216]\n",
      " [  118]\n",
      " [  196]\n",
      " [  693]\n",
      " [  253]\n",
      " [  155]\n",
      " [  611]\n",
      " [  245]\n",
      " [ 1650]\n",
      " [  309]\n",
      " [  157]\n",
      " [  153]\n",
      " [  952]\n",
      " [ 2237]\n",
      " [  152]\n",
      " [ 1218]\n",
      " [  444]\n",
      " [   97]\n",
      " [  517]\n",
      " [  389]\n",
      " [  500]\n",
      " [  952]\n",
      " [  216]\n",
      " [  271]\n",
      " [  225]\n",
      " [  286]\n",
      " [  116]\n",
      " [  242]\n",
      " [   85]\n",
      " [  213]\n",
      " [  191]\n",
      " [  349]\n",
      " [  211]\n",
      " [  270]\n",
      " [  781]\n",
      " [  116]\n",
      " [ 2803]\n",
      " [  499]\n",
      " [ 1053]\n",
      " [ 5515]\n",
      " [  126]\n",
      " [  136]\n",
      " [  234]\n",
      " [  112]\n",
      " [  108]\n",
      " [  146]\n",
      " [  110]\n",
      " [  151]\n",
      " [  164]\n",
      " [  670]\n",
      " [  151]\n",
      " [  712]\n",
      " [ 1313]\n",
      " [  213]\n",
      " [  108]\n",
      " [  593]\n",
      " [  171]\n",
      " [  209]\n",
      " [  146]\n",
      " [ 2577]\n",
      " [  143]\n",
      " [  110]\n",
      " [  113]\n",
      " [  143]\n",
      " [  112]\n",
      " [  119]\n",
      " [  147]\n",
      " [  109]\n",
      " [  208]\n",
      " [  133]\n",
      " [  111]\n",
      " [  111]\n",
      " [ 2554]\n",
      " [  109]\n",
      " [  113]\n",
      " [ 2479]\n",
      " [  302]\n",
      " [  324]\n",
      " [  317]\n",
      " [  316]\n",
      " [  399]\n",
      " [  292]\n",
      " [  293]\n",
      " [  295]\n",
      " [  346]\n",
      " [  312]\n",
      " [  139]\n",
      " [  224]\n",
      " [  303]\n",
      " [  693]\n",
      " [  300]\n",
      " [  218]\n",
      " [  316]\n",
      " [  212]\n",
      " [  313]\n",
      " [  140]\n",
      " [  299]\n",
      " [  294]\n",
      " [  408]\n",
      " [  316]\n",
      " [  343]\n",
      " [  344]\n",
      " [  232]\n",
      " [  305]\n",
      " [  136]\n",
      " [  328]\n",
      " [ 1573]\n",
      " [  335]\n",
      " [  406]\n",
      " [  312]\n",
      " [  524]\n",
      " [  354]\n",
      " [  314]\n",
      " [  290]\n",
      " [  317]\n",
      " [  217]\n",
      " [  302]\n",
      " [  292]\n",
      " [  127]\n",
      " [  400]\n",
      " [  548]\n",
      " [  205]\n",
      " [  410]\n",
      " [  118]\n",
      " [  394]\n",
      " [  446]\n",
      " [  307]\n",
      " [  337]\n",
      " [  358]\n",
      " [  294]\n",
      " [  234]\n",
      " [  303]\n",
      " [  127]\n",
      " [  118]\n",
      " [  310]\n",
      " [  199]\n",
      " [  394]\n",
      " [  298]\n",
      " [  228]\n",
      " [  307]\n",
      " [  323]\n",
      " [  299]\n",
      " [ 5542]\n",
      " [  307]\n",
      " [  307]\n",
      " [ 5487]\n",
      " [  117]\n",
      " [  311]\n",
      " [  138]\n",
      " [  321]\n",
      " [ 1896]\n",
      " [  824]\n",
      " [  331]\n",
      " [  298]\n",
      " [  134]\n",
      " [  280]\n",
      " [  120]\n",
      " [  311]\n",
      " [  315]\n",
      " [  290]\n",
      " [  903]\n",
      " [  448]\n",
      " [  310]\n",
      " [  834]\n",
      " [  596]\n",
      " [ 2493]\n",
      " [  262]\n",
      " [ 1341]\n",
      " [  467]\n",
      " [  433]\n",
      " [  445]\n",
      " [ 1950]\n",
      " [  448]\n",
      " [  407]\n",
      " [  453]\n",
      " [ 2277]\n",
      " [  463]\n",
      " [  460]\n",
      " [  423]\n",
      " [  414]\n",
      " [  356]\n",
      " [  160]\n",
      " [  450]\n",
      " [  382]\n",
      " [ 1777]\n",
      " [  392]\n",
      " [ 3689]\n",
      " [  517]\n",
      " [  462]\n",
      " [  360]\n",
      " [  398]\n",
      " [  396]\n",
      " [  567]\n",
      " [  872]\n",
      " [  373]\n",
      " [  419]\n",
      " [  397]\n",
      " [ 1281]\n",
      " [  347]\n",
      " [  492]\n",
      " [  465]\n",
      " [ 2059]\n",
      " [  540]\n",
      " [  431]\n",
      " [  401]\n",
      " [  361]\n",
      " [  483]\n",
      " [  270]\n",
      " [ 3689]\n",
      " [  826]\n",
      " [  338]\n",
      " [  433]\n",
      " [  427]\n",
      " [ 1204]\n",
      " [  127]\n",
      " [  502]\n",
      " [  151]\n",
      " [ 9308]\n",
      " [  139]\n",
      " [ 2560]\n",
      " [  375]\n",
      " [  480]\n",
      " [  405]\n",
      " [  401]\n",
      " [  320]\n",
      " [ 3102]\n",
      " [ 1093]\n",
      " [  385]\n",
      " [  375]\n",
      " [  153]\n",
      " [  432]\n",
      " [  403]\n",
      " [ 3689]\n",
      " [ 2493]\n",
      " [  494]\n",
      " [  446]\n",
      " [ 1480]\n",
      " [  798]\n",
      " [  434]\n",
      " [  334]\n",
      " [  233]\n",
      " [  459]\n",
      " [ 1521]\n",
      " [  431]\n",
      " [  447]\n",
      " [  537]\n",
      " [  445]\n",
      " [  289]\n",
      " [  437]\n",
      " [  490]\n",
      " [  489]\n",
      " [  456]\n",
      " [  249]\n",
      " [  399]\n",
      " [  488]\n",
      " [  339]\n",
      " [  248]\n",
      " [ 1190]\n",
      " [ 2069]\n",
      " [ 1552]\n",
      " [  414]\n",
      " [ 1477]\n",
      " [  333]\n",
      " [ 7218]\n",
      " [ 2744]\n",
      " [  130]\n",
      " [  276]\n",
      " [   99]\n",
      " [ 3327]\n",
      " [  259]\n",
      " [  714]\n",
      " [ 2304]\n",
      " [  357]\n",
      " [  457]\n",
      " [ 1565]\n",
      " [  342]\n",
      " [  184]\n",
      " [ 1255]\n",
      " [  563]\n",
      " [  365]\n",
      " [ 2865]\n",
      " [  451]\n",
      " [  738]\n",
      " [  482]\n",
      " [  586]\n",
      " [  392]\n",
      " [  475]\n",
      " [ 1275]\n",
      " [ 1438]\n",
      " [ 1438]\n",
      " [ 1314]\n",
      " [ 1085]\n",
      " [ 1050]\n",
      " [  151]\n",
      " [ 1573]\n",
      " [  153]\n",
      " [ 1161]\n",
      " [ 1583]\n",
      " [  706]\n",
      " [  151]\n",
      " [ 1493]\n",
      " [  163]\n",
      " [ 2589]\n",
      " [  159]\n",
      " [ 1657]\n",
      " [  163]\n",
      " [  357]\n",
      " [ 1261]\n",
      " [ 1054]\n",
      " [ 1047]\n",
      " [ 3216]\n",
      " [ 1095]\n",
      " [ 1344]\n",
      " [  151]\n",
      " [ 1600]\n",
      " [ 1043]\n",
      " [  271]\n",
      " [  350]\n",
      " [ 1332]\n",
      " [ 1335]\n",
      " [  488]\n",
      " [ 1746]\n",
      " [ 3996]\n",
      " [ 6683]\n",
      " [ 8513]\n",
      " [ 1025]\n",
      " [ 1052]\n",
      " [  149]\n",
      " [ 1013]\n",
      " [  196]\n",
      " [ 2833]\n",
      " [  157]\n",
      " [ 3926]\n",
      " [  155]\n",
      " [ 1928]\n",
      " [ 4135]\n",
      " [  347]\n",
      " [ 1253]\n",
      " [ 1612]\n",
      " [ 2643]\n",
      " [ 2539]\n",
      " [ 1082]\n",
      " [ 1878]\n",
      " [ 3237]\n",
      " [ 1051]\n",
      " [ 6315]\n",
      " [ 2062]\n",
      " [ 1023]], shape=(1000, 1), dtype=int16)\n",
      "tf.Tensor(\n",
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " ...\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]], shape=(1000, 3), dtype=int16)\n"
     ]
    }
   ],
   "source": [
    "#with open('input_datas/dummy/dummy__data.json') as f:\n",
    "#    data = json.load(f)\n",
    "    \n",
    "#with open('input_datas/dummy/dummy__labels.json') as f:\n",
    "#    labels = json.load(f)\n",
    "    \n",
    "#dataTF = tf.convert_to_tensor(data[0:1000], dtype=tf.int16)    \n",
    "#labelsTF = tf.convert_to_tensor(labels[0:1000], dtype=tf.int16)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ltpZN5v-CTmj"
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 860
    },
    "colab_type": "code",
    "id": "id-B0EsKCW0C",
    "outputId": "5207b6cd-2e02-47d2-e448-3cb389c6523e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_Layer_1 (Dense)        (None, 150)               300       \n",
      "_________________________________________________________________\n",
      "Dense_Layer_2 (Dense)        (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "Dense_Layer_3 (Dense)        (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 8,003\n",
      "Trainable params: 8,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def make_bert_model(inputSize=300, outputSize=3):\n",
    "  #Input Shape is (None, 300)\n",
    "  #Output Shape is (None, 3)\n",
    "  model = tf.keras.Sequential(name = 'BERT_Model')\n",
    "\n",
    "  #Model Params\n",
    "  layerSizes = [150, 50, outputSize]\n",
    "  activations = ['relu', 'relu', 'softmax']\n",
    "  assert len(layerSizes) == len(activations)\n",
    "\n",
    "  for idx, numNeurons in enumerate(layerSizes):\n",
    "    name = 'Dense_Layer_' + str(idx+1)\n",
    "    if idx == 0:\n",
    "      model.add(layers.Dense(numNeurons, input_dim=inputSize, activation=activations[idx], name=name))\n",
    "    else:\n",
    "      model.add(layers.Dense(numNeurons, activation=activations[idx], name=name))\n",
    "\n",
    "  return model\n",
    "\n",
    "def make_keywords_model(inputSize=300, outputSize=3):\n",
    "  #Input Shape is (None, 300)\n",
    "  #Output Shape is (None, 3)\n",
    "  model = tf.keras.Sequential(name = 'Keywords_Model')\n",
    "\n",
    "  #Model Params\n",
    "  layerSizes = [150, 50, outputSize]\n",
    "  activations = ['relu', 'relu', 'softmax']\n",
    "  assert len(layerSizes) == len(activations)\n",
    "\n",
    "  for idx, numNeurons in enumerate(layerSizes):\n",
    "    name = 'Dense_Layer_' + str(idx+1)\n",
    "    if idx == 0:\n",
    "      model.add(layers.Dense(numNeurons, input_dim=inputSize, activation=activations[idx], name=name))\n",
    "    else:\n",
    "      model.add(layers.Dense(numNeurons, activation=activations[idx], name=name))\n",
    "\n",
    "  return model\n",
    "\n",
    "#Print Model Summaries\n",
    "bertModel = make_bert_model(inputSize=1)\n",
    "print(bertModel.summary())\n",
    "\n",
    "#kwModel = make_keywords_model()\n",
    "#print(kwModel.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAxL4qoGCiDy"
   },
   "source": [
    "# Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LvCEo-KCkiB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.419747). Check your callbacks.\n",
      "  32/1000 [..............................] - ETA: 45s - loss: 16.1181 - acc: 0.0000e+00WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.715212). Check your callbacks.\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 9.1559 - acc: 0.3920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 182us/sample - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 193us/sample - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 153us/sample - loss: 9.5353e-04 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 184us/sample - loss: 2.6991e-04 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 225us/sample - loss: 8.7125e-05 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 469us/sample - loss: 3.2884e-05 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 195us/sample - loss: 1.5705e-05 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 213us/sample - loss: 6.7958e-06 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 184us/sample - loss: 3.1451e-06 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Compile the Models\n",
    "bertModel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#kwModel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train Model\n",
    "bertModel.fit(dataTF, labelsTF, epochs=10, batch_size=32)\n",
    "\n",
    "bertModel.save(os.path.join(wandb.run.dir, \"bertModel.h5\"))\n",
    "#kwModel.save(os.path.join(wandb.run.dir, \"kwModel.h5\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "G3n3us_M0d31.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
